\documentclass{beamer}
%\documentclass[handout]{beamer}

\usepackage{animate}

\begin{document}

\title{Introduction to Monte Carlo Simulation}
\author{Le Wang}

\maketitle


\begin{frame}
Itinerary: 
  
\begin{enumerate}
\item The Purpose of Monte Carlo Simulation and The Very Brief Account of Its Historical Development
\item Philosophical Debate over Randomness (Frequency vs. Subjective)
\item Randomness in Stata
  \begin{enumerate}
    \item Simulate a Fair Coin in Stata
    \item Simulate an Unfair coin in Stata
    \item How shoud we play craps?
  \end{enumerate}
\end{enumerate}

\end{frame}

\begin{frame}

Original purpose:

\bigskip

Find approximate solutions to certain mathematical equations.

\end{frame}

\begin{frame}
\textbf{Modern Version}

\bigskip

In 1947, scientists at the Rand Corporation were unable to solve their problem (related to nuclear weapon projects) using conventional, deterministic mathematical methods. They had the idea of using random experiments, which involves a large table of random digits.  

\end{frame}

\begin{frame}

Development of ways to generate random data. 

\bigskip

Being secret, their work required a code name: Monte Carlo!

\only<2->{
  \begin{figure}[htp!]
       \centering
       \includegraphics[width=4in, height=1.2in]{figures/Monte-Carlo_casino.png}
       \caption{Monte Carlo Casino, Monaco}
  \end{figure}
}

% https://en.wikipedia.org/wiki/Monte_Carlo_method 
% Ulam's uncle would borrow money from relatives to gamble.
\end{frame}

\begin{frame}[fragile]

\begin{figure}[htp!]
     \centering
     \includegraphics[width=4in, height=2.2in]{figures/rand-random_digits_cover.png}
     \caption{A Million Random Digits in 1955}
\end{figure}

\end{frame}


\begin{frame}[fragile]

\begin{figure}[htp!]
     \centering
     \includegraphics[width=4in, height=2.2in]{figures/rand-random_digits_inside.png}
     \caption{A Million Random Digits in 1955}
\end{figure}

\end{frame}


\begin{frame}[fragile]

\begin{figure}[htp!]
     \centering
     \includegraphics[width=4in, height=1.2in]{figures/randomness_joke.png}
     \caption{Huh, Random?}
\end{figure}

\end{frame}


\begin{frame}

Monte Carlo Simulation : generating random data (samples) from a probability distribution.

\bigskip

\textbf{Creation of Uncertainty/Randomness}


\end{frame}

\begin{frame}

Interpretation of Randomness: \textbf{Frequency} vs \textbf{Subjective}

\bigskip
\textbf{Frequency Interpretation:} You judge a sample by the way it turns out.

\bigskip
\textbf{Subjective Interpretation:} You judge a sample by the way it is produced. We know how it is produced (on our computer) in our computer!

\end{frame}

\begin{frame}
Algorithms to produce randomness have been refined over the years. 

\bigskip
We now understand that truly random events do occur on the atomic level. Today, cutting-edge quantum generators produce truly random numbers from the toss of Nature's perfect quantum dice. 


\end{frame}

\begin{frame}

\textbf{Randomness in Stata}

\bigskip

We safely leave this philosophical debate and practical examination of randomness behind us. Assume that it has been done correctly for our purpose.


\end{frame}


\begin{frame}

When we say that a random variable in Stata \emph{simulates} (or represents) some unknown quantity in real life, we mean that

\bigskip

Any event for this simulated random variable is, from the perspective of our current information and beliefs, just as likely as the same event for the real unknown quantity. 

\end{frame}

\begin{frame}
For example,

\bigskip

If the unknown outcome of a coin toss has a probability 0.50 of equaling 1 (or tails), then the random variable in R should also have probability .50 of equaling 1 after the next recalculation of the computer. 

\end{frame}

\begin{frame}
\textbf{Stata Resources}

\bigskip

\textbf{How to generate random numbers in Stata} \url{https://blog.stata.com/2016/03/10/how-to-generate-random-numbers-in-stata/}

\bigskip

\textbf{Bill Gould's blog posts on Using Stata's random-number generators}



\end{frame}



\begin{frame}

\bigskip

  \begin{center}
    \textbf{Application I: Inverse Transform Method}  
  \end{center}

\end{frame}


\begin{frame}

\textbf{Reproduction Property} Let $X$ be a real-valued random variable with distribution function $F$, and let $U$ be uniformly distributed between zero and one. Then,

$$
F^{-1}(U) \sim F_X 
$$


\end{frame}

\begin{frame}
\textbf{Example: Exponential Distribution}

\bigskip

$$
\begin{eqnarray*}
f(x;\lambda) & = & \lambda e^{-\lambda x}, \quad x\geq 0 \\
F(x;\lambda) & = & (1-e^{-\lambda x}), \quad x \geq 0 \\
F^{-1}(x; \lambda) & = & \frac{-\ln(1-u)}{\lambda}, \quad 0 \leq u \leq 1
\end{eqnarray*}
$$


\bigskip

\textbf{Stata Example:} \textt{Stata\_example\_monte\_carlo01.do}

\end{frame}


\begin{frame}

\bigskip

  \begin{center}
    \textbf{Application II: One-Dimension Monte Carlo Integration}  
  \end{center}

\end{frame}


\begin{frame}
Suppose that we want to compute

$$
  \theta = \int^1_0 g(x) dx
$$

We cannot compute $\theta$ analytically, we can use numerical methods. The key is to realize that this expression is nothing but 

\begin{eqnarray*}
  \theta & = & \int^1_0 g(x) \cdot 1 \cdot dx \\
         & = & \mathbb{E}[g(x)]
\end{eqnarray*}

Remember that $1$ is the density function of the standard uniform.

\end{frame}

\begin{frame}

$$
\mathbb{E}[g(x)] = \int g(x) f(x) dx
$$

\begin{eqnarray*}
  \theta & = & \int^1_0 g(x) \cdot 1 \cdot dx \\
         & = & \mathbb{E}[g(x)]
\end{eqnarray*}
\end{frame}

\begin{frame}
If we know that 
\begin{eqnarray*}
  \theta & = & \int^1_0 g(x) dx \\
         & = & \mathbb{E}[g(U)] \quad U \sim U(0,1)
\end{eqnarray*}

We can do the following
  \begin{enumerate}
    \item<2-> Generate a random set of values ($U_1,U_2, U_3, \dots, U_N$) distributed from $U(0,1)$ and independent
    \item<3-> Estimate $\theta$ with 
      $$
        \widehat{\theta_n} = \frac{g(U_1)+g(U_2)+\dots+g(U_N)}{N}
      $$
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
\textbf{Example:} Suppose that we wish to estimate 

$$\int^1_0 x^3 dx = \frac{1}{4}=.25$$

\bigskip

Lets look at our Stata example: \texttt{Stata\_example\_monte\_carlo02.do}



\end{frame}


\begin{frame}
\textbf{Extensions}
  \begin{enumerate}
    \item You can extend this to obtain integration over a suppose different from [$0,1$]. For example,
    
    \begin{eqnarray*}
    \theta & = & \int^3_1 (x^2 + x) dx \\
           & = & 2 \cdot \int^3_1 (x^2+x) \frac{1}{2} dx \\
           & = & 2 \mathbb{E}[X^2 + X]
    \end{eqnarray*}
    
    Note that $X$ is distributed from $U(1,3)$ (Uniform distribution with support [$1,3$]) whose density is $\frac{1}{3-2}=\frac{1}{2}$. 
    
    
    \item You can also simulate discrete variables based on the standard uniform distribution. 
  \end{enumerate}
\end{frame}


\begin{frame}
Simulating uniformly distributed variables (other than standard uniform)

\begin{enumerate}
  \item Draw directly using Stata built-in command \texttt{runiform(min=,max=)}
  \item Draw indirectly using standard uniform first and then manipulate it (with addition and multiplication) into a uniform distribution with different support. \textbf{In your homework, you will be asked to try this method.}
\end{enumerate}


Lets look at our Stata example: \texttt{Stata\_example\_monte\_carlo02.do}

\end{frame}

\begin{frame}[fragile]
\begin{center}

\textbf{Appliation 3: Simulate Coin Toss and Dice Rolling}

\end{center}

Lets look at our Stata example: \texttt{Stata\_example\_monte\_carlo03.do} and \texttt{Stata\_example\_monte\_carlo04.do}




\end{frame}


\end{document}

