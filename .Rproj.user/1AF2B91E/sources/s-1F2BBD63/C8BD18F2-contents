---
title: "Statistics for Decision Making: Broad Introduction"
subtitle: "A Naive Approach for Forecasting Time Series"
author: "Le Wang"
header-includes:
  - \usepackage{tikz}
date: "`r Sys.Date()`"
output: beamer_presentation
---

```{r, echo=FALSE}
options(width=60)
```
  


## Forecasting: What are we trying to do?

We first have to accept the fact that what we are trying to forecast or predict is a random variable subject to random disturbances. 

There is a part that is not predictable at all, no matter how hard we try. 

$$
\text{Series} = \textbf{Signal} + \textbf{Noise}
$$

1. **Signal** A collection of systematic, predictable components}
2. **Noise** Unpredictable, erratic, abrupt changes/random components

## Forecasting: What are we trying to do?

How we treat the signal part leads to two different approaches in practice. The first approach considers the signal as the product of a \emph{gradually} evolving trend and \emph{smoothly} varying cycle. Whatever is erratic or unsystematic is treated as noise (or residual). This approach is called \textbf{smoothing}.

$$
\textbf{Smoothing}:\quad \text{Series} = \text{Fit} + \text{Residual}
$$

\noindent The second approach formally models the relation between the outcome of interest and its predictors such as past outcomes and other covariates.

$$
\textbf{Modeling}:\quad \text{Series} = \text{Model} + \text{Error}
$$

   
## Forecasting: A Naive Way to Decompose a Variable    
   
What will next period's sales tax revenue (quarterly data) be? **Use your common sense!**

![](plano.png)


## Forecasting: A Naive Way to Decompose a Variable    

**Question:** What are the important features of this variable?

## Forecasting: A Naive Way to Decompose a Variable    


1. Trend
2. Seasonality
3. Something else

## Forecasting: A Way to Decompose a (time series) Variable    

$$Y = T+C+S+I$$
or 

$$Y = T\times C \times S \times I$$

Equivalent: 

$$\log(Y) = \log(T)+\log(C)+\log(S)+\log(I)$$

1. Trend
2. Seasonality
3. Something else
    1. Cycles
    2. Irregular component
   
   
## Forecasting: A Naive Way to Decompose a Variable    

Let's define each component (Chapter 6.1 in Forecasting: Principles and Practice)

\bigskip

**Trend** A **long-term** increase or decrease in the data, as opposed to *local*, *current*, *recent* trend. (It does not have to be linear)

\bigskip

**Question: Is this a trend?** A recent trend in stock prices when prices trend up in a "bull" market or down in a "bear" market. 

   
## Forecasting: A Naive Way to Decompose a Variable    

![](ec513_intro_time_series_trend_gdp.png)

## Forecasting: A Naive Way to Decompose a Variable    

**Cycle** The data exhibit rises and falls that are *not of a fixed period*. (Roughly speaking)

\bigskip

The term is a bit "misleading": Does not resemble the regular periodic ossillation of a function such as sine and cosine. 

\bigskip

**Business cycles**

## Cycles


![](ec513_intro_time_series_cycle_unemployment.png)

## Statistical Cycles vs. Deterministic Cycles

![](ec513_intro_time_series_cycle_deterministic.png)

## Seasonality

**Seasonality** A time series is affected by seasonal factors such as the time of year, or the day of week. 

## Seasonality

![](ec513_intro_time_series_seasonality_electricity.png)

## Seasonality

![](ec513_intro_time_series_seasonality_education.png)

## Seasonality

![](ec513_intro_time_series_seasonality_marriage.png)

## Seasonality

Petra Persson's paper

\bigskip

Swedish survivor insurance reform: widowed are entitled to some benefits upon her husband's dealth, satisfying some criteria

The amount of benefits for marriages after January 1990 were drastically reduced. 

\bigskip
$\implies$

"retimed-marriages" and "extra marriages" (of low match quality)

**Question:** What do you think would happen to those husbands in these marriages?




## Working with Time Series in R

Many of you are more familiar with macro type of data such as inflation and interest rates for a particular country or region. This type of data are time series. 

Such data requires some specical handling in order to fully expolit the time series structure. It is thus important to learn how to work with time series data in \texttt{R}.


## Working with Time Series in R

In what follows, we will learn two basic things:

1. Date and Time in `R` (Own Reading)
2. Time Series Plots
    1. \tt{quantmod()}
    2. \tt{plot()}
    3. \tt{ggplot2()}
3. Classical Decomposition of Time Series (Not particularly recommended, but sufficient for illustration).
4. STL Decomposition

## Working with Time Series in R

We illustrate these methods using actual data on an important variable in the U.S.. 


---

How Important? From [Everybody Lies](https://www.amazon.com/Everybody-Lies-Internet-About-Really/dp/0062390856/ref=sr_1_1?ie=UTF8&qid=1535678365&sr=8-1&keywords=everybody+lies)

![](figures/story_UNRATE01.png)

---

![](figures/story_UNRATE02.png)


---

![](figures/story_UNRATE03.png)


## Working with Time Series in R

We illustrate these methods using actual data on unemployment rates in the U.S.. 

\bigskip

The data on (seasonally adjusted) **unemployment rates** from St. Louis Fed's website, which is available for viewing at \url{https://fred.stlouisfed.org/series/UNRATE}

## Working with Time Series in R

Let's obtain the data first using \tt{quantmod()}. 

**Step 1**. We need to let R know where this function (or tool) is located.

**Step 2**. We can grab the data using \tt{getSymbols()}


## Working with Time Series in R

```{r echo=TRUE, message=FALSE,warning=FALSE, error=FALSE, strip.white=FALSE, collapse=TRUE, tidy=TRUE,size='tiny'}
library(quantmod)
getSymbols('UNRATE',src='FRED')
```

1. The first argument is **variable name**, which can also be found at the end of the website link, 
2. The second argument \texttt{src = 'FRED'} instructs R to obtain the data from St. Louis Fed. 

## Working with Time Series in R

```{r}
head(UNRATE)
```

**Note**: only one column of data, which is called \texttt{UNRATE}. The first column is not actual data, but row names. 

## Working with Time Series in R

```{r}
tail(UNRATE)
```

## Working with Time Series in R (Approach 1)

**First approach** to plotting the data is to use \texttt{chartSeries()}, a built-in command that comes with the package \texttt{quantmod}.

```{r, fig.width=8, fig.height=5}
  chartSeries(UNRATE, theme="white")
```


## Working with Time Series in R (Approach 2)

```{r, fig.width=8, fig.height=5}
plot(UNRATE)
```


## Working with Time Series in R (Approach 2)

```{r, fig.width=8, fig.height=5}
plot(UNRATE)
abline(h = 10, col = "salmon")
```


## Working with Time Series in R (Approach 3)

The **third** approach is to use **ggplot2**, one of the most elegant and most versatile systems for making graphs. 

1. Implements the *grammar of graphics*, a coherent system for describing and building graphs
2. More faster by learning one system and applying it in many places. 

## Working with Time Series in R (Approach 3)

Here we need a dataset (in the data frame) with two variables, one on the $x$ axis and the other $y$-axis. 

## Working with Time Series in R (Approach 3)

```{r}
  # 1. Convert it to a data frame
  data.unrate <- data.frame(UNRATE)
  data.unrate$date <- as.Date(rownames(data.unrate))
    colnames(data.unrate)[1] = 'unrate'
    head(data.unrate)


```

## Working with Time Series in R (Approach 3)

**A Graphing Template**

```{r, eval=FALSE}
ggplot(data = <DATA>) +
  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))
```

## Working with Time Series in R (Approach 3)

```{r, fig.width=8, fig.height=5}
  library(ggplot2)
  ggplot(data=data.unrate) + 
    geom_line(mapping = aes(x=date,y=unrate))
```

## Working with Time Series in R (Approach 3)

```{r, fig.width=8, fig.height=5}
  library(ggplot2)
  ggplot(data=data.unrate) + 
    geom_line(mapping = aes(x=date,y=unrate)) + 
    theme_bw()  
```

## Working with Time Series in R (Approach 3)

```{r, fig.width=8, fig.height=5, message=FALSE}
  library(ggplot2)
  ggplot(data=data.unrate) + 
    geom_line(mapping = aes(x=date,y=unrate)) + 
    geom_smooth(mapping = aes(x=date,y=unrate)) + 
    theme_bw()  
```

## Working with Time Series in R (Efficient Approach 3)

```{r, fig.width=8, fig.height=5, message=FALSE}
  library(ggplot2)
  ggplot(data=data.unrate, mapping = aes(x=date,y=unrate)) + 
    geom_line() + 
    geom_smooth() + 
    theme_bw()  
```

## Working with Time Series in R (Efficient Approach 3)

```{r, eval=FALSE}
  ggplot(data=data.unrate, mapping = aes(x=date,y=unrate)) + 
    geom_line() + 
    geom_smooth() + 
    theme_bw() 
```

**Painting on a Canvas**

1. Creates an empty canvas 
2. Adds a layer of connected line (geometric objects **GEOM** functions) 
    1. The \texttt{mapping} argument is always paired with \texttt{aes()}.
    2. An *aesthetic* is a visual property of the objects in your plot. You can change, e.g., the shape or the size of your line. 
3. Adds another layer of smoothed line
4. Replace the background with black and white canvas.

## Some Simple Forecasting Methods

Let's look at some very simple methods for forecasting this important variable. Although simple, they could be rather effective in practice. 

  1. Average method
  2. Naive method
  3. Seasonal naive method
  4. Drift method

## Some simple forecasting methods

\fontsize{13}{14}\sf

### Average method

  * Forecast of all future values is equal to mean of historical data $\{y_1,\dots,y_T\}$.
  * Forecasts: $\hat{y}_{T+h|T} = \bar{y} = (y_1+\dots+y_T)/T$

\pause

### Naïve method

  * Forecasts equal to last observed value.
  * Forecasts: $\hat{y}_{T+h|T} =y_T$.
  * Consequence of efficient market hypothesis.

---

These two approaches are extreme cases, and there are two equilvalent to think of them. 

1. We can think of the average method as using all the data point, but the naive method uses only one data point. A less extreme way may be to use some data points (perhaps a subset?). 

--- 

2. We can also rewrite the average method and the naive method as follows

\begin{align*}
\hat{y}_{T+h|T} & = \frac{1}{T}\times y_1 +\frac{1}{T}\times y_2 + \dots + \frac{1}{T}\times y_T \\
\hat{y}_{T+h|T} & = 0\times y_1 +0\times y_2 + \dots + 1\times y_T 
\end{align*}

\pause

Perhaps a different weighting scheme?

---

### Seasonal naïve method

  * Forecasts equal to last value from same season.
  * Forecasts: $\hat{y}_{T+h|T} =y_{T+h-m(k+1)}$, where $m=$ seasonal period and $k$ is the integer part of $(h-1)/m$.

---

**How do we take into account trend?**

Hint: You can think of an average method and a naive method, too!

---

### Drift method (taking into some trend, if any)

 * Forecasts equal to last value plus average change.
 * Forecasts:\vspace*{-.7cm}

 \begin{align*}
 \hat{y}_{T+h|T} & =  y_{T} + \frac{h}{T-1}\sum_{t=2}^T (y_t-y_{t-1})\\
                 & = y_T + \frac{h}{T-1}(y_T -y_1).
 \end{align*}\vspace*{-0.2cm}

   * Equivalent to extrapolating a line drawn between first and last observations.

---

Naive trend method may be

\begin{align*}
\hat{y}_{T+h|T} & =  y_{T} + h (y_T-y_{T-1})
\end{align*}


## Some simple forecasting methods in R

  * Mean: `meanf(y, h=20)`
  * Naïve:  `naive(y, h=20)`
  * Seasonal naïve: `snaive(y, h=20)`
  * Drift: `rwf(y, drift=TRUE, h=20)`

---

```{r unrate, warning=FALSE, message=FALSE, echo=FALSE}
library(quantmod)
library(fpp2)
getSymbols("UNRATE",src="FRED")
attr(UNRATE,'frequency') <- 12
time <- ts(UNRATE, start = 1948, frequency = 12)

time2 <- window(time,start=1948,end=c(2018,2))

# Plot some forecasts
autoplot(time) +
  autolayer(meanf(time2, h=5), PI=FALSE, series="Mean") +
  autolayer(naive(time2, h=5), PI=FALSE, series="Naïve") +
  autolayer(snaive(time2, h=5), PI=FALSE, series="Seasonal naïve") +
  autolayer(rwf(time2, drift=TRUE, h=5), PI=FALSE, series="Drift") +
  ggtitle("Forecasts for monthly unemployment rates with Data from Jan 1948 to Feb 2018") +
  xlab("Date") + ylab("Unemployment Rates") +
  guides(colour=guide_legend(title="Forecast"))
```
  
---

```{r unrate2, warning=FALSE, message=FALSE, echo=FALSE}

time2 <- window(time,start=2010,end=c(2018,2))
time3 <- window(time,start=2010)

# Plot some forecasts
autoplot(time3) +
  autolayer(meanf(time2, h=5), PI=FALSE, series="Mean") +
  autolayer(naive(time2, h=5), PI=FALSE, series="Naïve") +
  autolayer(snaive(time2, h=5), PI=FALSE, series="Seasonal naïve") +
  autolayer(rwf(time2, drift=TRUE, h=5), PI=FALSE, series="Drift") +
  ggtitle("Forecasts for monthly unemployment rates with Data from Jan 2010 to Feb 2018") +
  xlab("Date") + ylab("Unemployment Rates") +
  guides(colour=guide_legend(title="Forecast"))
```

## Questions to think

**Question 1:** Was Trump's administration effective in improving the job market? 

\bigskip

**Question 2:** What do you mean by recent period?

\pause
\bigskip

**IT is very arbitrary!!!!**

